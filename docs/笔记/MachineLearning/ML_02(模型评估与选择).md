> First version on 2022-1-22
>
>Last version on 2022-1-22
>
>Author :FeynmanRP

# 模型评估与选择

## 经验误差与过拟合

通常我们把分类错误的样本占样本总数的比例称为“错误率”，即如果在$m$个样本中有$a$个样本分类错误，则错误率$E=a/m$，相应的，我们把$1-a/m$称为“精度”。更一般的我们把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”，学习器在训练集上的误差称为“经验误差”，在新样本上的误差称为“泛化误差”。

我们希望我们的学习器在新样本中表现的较好。为达到这样的目的，我们训练样本应该学出适用于所有潜在样本的“普遍规律”。然而当学习器把训练样本学得“太好了”的时候，可能把训练样本自身的一些特点当作了所有潜在样本的一般性质，这导致模型的泛化能力下降，我们称这种现象叫做“过拟合”，反之称为“欠拟合”。

## 评估方法

### 留出法
“留出法”（hold-out）直接将数据D分成两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，即$D=S\cup T$,$S\cup T=\emptyset$,一般采用“分层采样”，让两个集合的样本类别比例相似，采用若干次随机划分、重复进行评估后取平均值作为留出法的评估结果。一般来说，将大约$2/3~4/5$的样本用于训练，剩余样本用于测试。

### 交叉验证法
“交叉验证法”(cross validation)先将数据划分为k个大小相似的互斥子集，即$D=D_1\cup D_2...\cup D_k,D_i\cap D_j=\emptyset$,每个样本保持数据分布一致性，每次使用k-1个子集作为训练集，剩下那个作为验证集，重复k次，称为
“k折交叉验证”，通产随机划分重复p次，最后取这p次k折交叉验证的平均值，常见的有“10次10折交叉验证”。

